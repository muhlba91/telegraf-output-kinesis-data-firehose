[[outputs.firehose]]
  ## General AWS settings.
  region = "eu-west-1"

  ## AWS credentials can be sourced from one of the following configurations.
  ## Please ensure to set the correct parameters depending on your authentication.
  access_key = ""
  secret_key = ""
  #role_arn = ""
  #web_identity_token_file = ""
  #role_session_name = ""
  #profile = ""
  #shared_credential_file = ""
  #endpoint_url = ""

  ## The name of the Amazon Kinesis Data Firehose Delivery Stream.
  ## The stream must exist prior to starting telegraf!
  streamname = "DeliveryStreamName"

  ## Enables debug logging for troubleshooting.
  #debug = false

  ## Batch messages for ingesting them to the stream.
  ## The maximum batch size is 500 as per AWS documentation.
  ## All ingested metrics will be sent to AWS but this parameter
  ## defines the maximum size the plugin sends at once.
  batchsize = 500

  ## Output formatting options.
  ## These are mostly used to normalize incoming data into a JSON format.
  #[format]
    ## Flattens all tags and fields into top-level keys.
    #flatten = false
    ## Normalizes all keys to account for:
    ## 1. conversion to lower case, and
    ## 2. replacement of spaces (' ') with underscores ('_')
    #normalize_keys = false
    ## Renames the 'name' key to the provided value.
    ## This can be useful to provide a more descriptive column name, e.g. if used with AWS Athena.
    #name_key_rename = ""
    ## The plugin interprets the timestamp as a unix timestamp.
    ## In some cases timestamp represents a value according to RFC3339.
    ## To allow for these values, set this parameter to true.
    #timestamp_as_rfc3339 = false
    ## Defines the unix timestamp precision.
    #timestamp_units = "1ms"
